<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[LDA线性判别分析]]></title>
    <url>%2FBlog%2Farchives%2F3a6e9ae0.html</url>
    <content type="text"><![CDATA[LAD概括LAD主要用于在高维数据的分类中，将数据按照线性模型进行降维；使得数据得到很好的分类同时避免数据过度拟合，与PAC不同的是 LAD主要用于有监督的学习，用于对目标分类;约束条件则是类间的协方差最大，同类内的协方差最小化PAC则是无监督的学习，将样本投影到几个正交的方向，同时同类内的方差越大越好，尽可能的保留样本的全部信息 两类的LAD问题可以看作是把所有样本都投影到一个方向上，然后在这个一维空间中确定一个分类的阈值。过这个阈值点且与投影方向垂直的超平面就是两类的分类面。 公式推导 映射直线y=wTx 约束条件则是类间的协方差最大，同类内的协方差最小化 J=||wTμ0−wTμ1||22/wT(∑0+∑1)w=wT(μ0−μ1)(μ0−μ1)Tw/wT(∑0+∑1)w 这里涉及到欧氏距离也就是矩阵的平方等于 原矩阵*矩阵的转置 目的使得约束条件J最大化类间协方差矩阵 Sb=(μ0−μ1)(μ0−μ1)T类间协方差矩阵 Sw=∑x∈D0(x−μ0)(x−u0)T+∑x∈D1(x−μ1)(x−u1)T重写J: J=wTSbw/wTSww 关于W的确定，由于分子分母是w的平方，已经将w实数化；因此方程的解与w的大小已经无关，仅仅是方向上有关了 拉格朗日乘子法令wTSww=1c(w)=wTSbw−λ(wTSww−1)涉及到矩阵的求导dc/dw=2Sbw−2λSww=0Sbw=λSwwSbW 类间散度矩阵 方向是固定的U0-U1w=Sw -1(u0-u1) 基于两个以上特征值的分类原理是一样的，在计算类间散度矩阵是多了两个参数SB=∑i=1-c Ni(mmi−mm)(mmi−mm)Tmm 是全局均值，而 mmi 和 Ni 是每类样本的均值和样本数。 求出特征值和特征序列矩阵 S−1WSB =W按照特征值排序，将原来多维度的空间映射到对应的空间 代码实现数据获取与格式整理123456789101112131415161718192021222324252627282930313233343536373839404142434445#coding=UTF-8import numpy as npimport pandas as pd from sklearn.preprocessing import LabelEncoderfrom matplotlib import pyplot as plt####构造索引与对应的名称关系feature_dict = &#123;i:label for i,label in zip( range(4), ('sepal length in cm', 'sepal width in cm', 'petal length in cm', 'petal width in cm', ))&#125;'''&#123;0: 'sepal length in cm', 1: 'sepal width in cm', 2: 'petal length in cm', 3: 'petal width in cm'&#125;'''##读取数据df=pd.io.parsers.read_csv( filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None, sep=',', )###定义列名df.columns=[l for i,l in sorted(feature_dict.items())]+["classLab"]#删除文件末尾的空行df.dropna(how="all",inplace=True)###看一下最后10行时啥样#print(df.tail())''' sepal length in cm sepal width in cm petal length in cm \145 6.7 3.0 5.2 146 6.3 2.5 5.0 147 6.5 3.0 5.2 148 6.2 3.4 5.4 149 5.9 3.0 5.1 petal width in cm classLab 145 2.3 Iris-virginica 146 1.9 Iris-virginica 147 2.0 Iris-virginica 148 2.3 Iris-virginica 149 1.8 Iris-virginica ''' 将类别数字化12345678910X=df[[0,1,2,3]].values #获取四种属性值y=df['classLab'].values #获取类别名enc = LabelEncoder()label_encoder = enc.fit(y)y = label_encoder.transform(y) + 1label_dict = &#123;1: 'Setosa', 2: 'Versicolor', 3:'Virginica'&#125;# print(len(y))'''数据处理完成 计算每类花对应的特征值的均值1234567891011121314##分别对三种花求其在4种属性上的均值np.set_printoptions(precision=4)mean_vectors=[]for i in range(1,4): ##对4中属性150 X 4 的矩阵按列求均值 mean_vectors.append(np.mean(X[y==i],axis=0)) #print('mean Vector calss %s: %s\n' %(i,mean_vectors[i-1]))'''mean Vector calss 1: [5.006 3.418 1.464 0.244]mean Vector calss 2: [5.936 2.77 4.26 1.326]mean Vector calss 3: [6.588 2.974 5.552 2.026]''' 类内散度矩阵1234567891011121314151617S_W=np.zeros((4,4))for cl,mv in zip(range(1,4),mean_vectors): ####每个类的类内散度矩阵 class_sc_mat=np.zeros((4,4)) for row in X[y==cl]: ##把对应的值与特征值进行运算 ''' [1,第一个特征值 2, 第2个特征值 3, 第3个特征值 4 第4个特征值 ] ''' row, mv = row.reshape(4,1), mv.reshape(4,1) class_sc_mat+=(row-mv).dot((row-mv).T) S_W+=class_sc_mat 类间散度矩阵123456789overall_mean=np.mean(X,axis=0)S_b=np.zeros((4,4))for i,men_vector in enumerate(mean_vectors): ###获取样本数目 n=X[y==i+1,:].shape[0] men_vector=men_vector.reshape(4,1) overall_mean=overall_mean.reshape(4,1) S_b+=n*(men_vector-overall_mean).dot((men_vector- overall_mean).T)print('between-class Scatter Matrix:\n', S_b) 获取特征值和特征向量123456eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_b))for i in range(len(eig_vals)): eigvec_sc = eig_vecs[:,i].reshape(4,1) print('\nEigenvector &#123;&#125;: \n&#123;&#125;'.format(i+1, eigvec_sc.real)) print('Eigenvalue &#123;:&#125;: &#123;:.2e&#125;'.format(i+1, eig_vals[i].real)) 根据特征值大小选取特征向量降维123eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True)W = np.hstack((eig_pairs[0][1].reshape(4,1), eig_pairs[1][1].reshape(4,1))) 映射到新的空间12X_lda = X.dot(W)assert X_lda.shape == (150,2) 作图123456789101112131415161718192021222324252627282930313233343536def plot_step_lda(): ax = plt.subplot(111) for label,marker,color in zip( range(1,4),('^', 's', 'o'),('blue', 'red', 'green')): plt.scatter(x=X_lda[:,0].real[y == label], y=X_lda[:,1].real[y == label], marker=marker, color=color, alpha=0.5, label=label_dict[label] ) plt.xlabel('LD1') plt.ylabel('LD2') leg = plt.legend(loc='upper right', fancybox=True) leg.get_frame().set_alpha(0.5) plt.title('LDA: Iris projection onto the first 2 linear discriminants') # hide axis ticks plt.tick_params(axis="both", which="both", bottom="off", top="off", labelbottom="on", left="off", right="off", labelleft="on") # remove axis spines ax.spines["top"].set_visible(False) ax.spines["right"].set_visible(False) ax.spines["bottom"].set_visible(False) ax.spines["left"].set_visible(False) plt.grid() plt.tight_layout plt.savefig("LDA.png")plot_step_lda() Reference推荐看老外的英文介绍老外的翻译版机器学习-线性判别分析.周志华xLAC拉格朗日乘子法PAC二分类LAD]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验进展]]></title>
    <url>%2FBlog%2Farchives%2Fe5775d07.html</url>
    <content type="text"><![CDATA[2019-03-01分别对每一类在各个组织中的基因数目进行统计 关于各个组织间对应基因数目的统计 A2-D5 vs At-Dt 一共有一共有18,689对亚基因组同源基因pairs，下图是各个组织中每种分类的基因对的数目 A2-At vs D5-Dtya]]></content>
  </entry>
  <entry>
    <title><![CDATA[梯度上升算法实现]]></title>
    <url>%2FBlog%2Farchives%2F1df1d0ad.html</url>
    <content type="text"><![CDATA[梯度上升算法概念例如我们存在一个函数 f(x)=X2+4x要求它的极值，主要就是求偏导为0的那个点的坐标像这种简单的函数直接使f(x)‘为0就行 但在真实的情况中函数没有我们想象的这么简单，那就只能让我们一步一步的逼近极值点 X i+1=X i+a*f(x)‘ a为步长控制更新的幅度，当函数值无限逼近极值点时停止迭代过程 代码实现12345678910111213141516171819202122232425#coding=UTF-8'''梯度上升算法的简单实现原函数f(x)=x2+4x'''def Gradient(): ##定义导函数 def gradientPrim(X): return -2*X+4 x_old=1 x_new=0 ###控制步长度 alpha=0.01 #####控制梯度阈值 presision=0.0000001 while abs(x_new-x_old)&gt;presision: x_old=x_new #将提升后的值代入导函数求得新的坐标点； #当导函数无限的笔记0的时候，x_old与x_new也就无限逼近了 x_new=x_old+alpha*gradientPrim(x_old) print(x_new)Gradient() 总结 梯度上升与梯度下降算法主要的一个思想 当函数达到极值点时，导函数为0,这时新的坐标点与旧的坐标点之间的距离将无限的逼近 逼近的精度受到判断指标presision影响 同时步长主要影响的是迭代的次数 参考https://blog.csdn.net/c406495762/article/details/77723333]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logistic回归]]></title>
    <url>%2FBlog%2Farchives%2Fb10b3e49.html</url>
    <content type="text"><![CDATA[概念 logistics回归是一种二分类的算法，它利用sigmoid函数将样本数据映射在[0,1]空间 假设我们的一个样本有n个属性x 1…x n,那就需要有n个参数构成的矩阵，将其构造成一个线性模型 对每一个样本我们都可以使用这个参数矩阵去计算一个条件概率； P(y=1|x,w)=0.51P(y=1|x,w)=0.99同一个样本在不同的参数矩阵w下，对样本估计为1的概率不同，我们需要取得最大的概率 扩展到整个样本， 又因为样本之间是独立同分布的，就可以用每个样本的概率做累乘 做完乘法之后将会得到一个关于w矩阵的概率函数，我们训练的目的就是要寻找一组w参数来使得我们正确判断y=1与y=0的概率达到最大 关于累乘的求导，通常使用ln函数变成累加，方便计算 这就回到了对函数求极值点的问题了，数据已经有了接下来就是要梯度法进行求解就行 在梯度下降过程中使用矢量法进行替换求解公式推导 矢量化在利用梯度求解过程中使用到矢量化的思想 在迭代的过程中设置w参数的初始值为 n x 1 的矩阵 接下来往公式里套就行了代码实现123456789101112131415161718192021222324252627282930313233343536373839404142#ocding=UTF-8####罗杰斯特回归##import numpy as np ##读取文件数据##def loadDataSet(): dataMat=[] labelMat=[] fr=open("testSet.txt") for line in fr.readlines(): linerArr=line.strip().split() dataMat.append([1,float(linerArr[0]),float(linerArr[1])]) labelMat.append(int(linerArr[2])) fr.close() return(dataMat,labelMat)def sigmoid(x): return(1.0/(1+np.exp(-x)))####梯度上升法####def gradAscent(dataMatin,labelMatin): dataMatout=np.mat(dataMatin) labelMatout=np.mat(labelMatin).transpose() m,n=np.shape(dataMatout) alpha=0.001 maxCycle=500 ###初始参数的矩阵 weights=np.ones((n,1)) for k in range(maxCycle): ##这里已经把累加算了，得到m x 1矩阵 h=sigmoid(dataMatout*weights) error=labelMatout-h #####把x矩阵转置构造 n x m 矩阵 weights=weights+alpha*dataMatout.transpose()*error return weightsdataMat,labelMat=loadDataSet()print(gradAscent(dataMat,labelMat)) 参考https://blog.csdn.net/lgb_love/article/details/80592147https://blog.csdn.net/c406495762/article/details/77723333最大似然法矢量化]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高斯消元法]]></title>
    <url>%2FBlog%2Farchives%2Feccd8894.html</url>
    <content type="text"><![CDATA[高斯消元法介绍 高斯消元法主要用在解线性方程，当前实现的仅仅是有唯一解的一个算法1234x1 x2 x3 val1 2 3 53 4 4 73 4 5 6 将线性方程变成一个上三角矩阵的过程1 2 3 3 40 1 2 3 40 0 1 2 30 0 0 3 3 从这个矩阵也不难看出是一个n x (n+1)类型 实现步骤 实现上三角转换主要是进行遍历，遍历的过程主要就是让每行的参数变为0 第一行遍历剩下的n-1行第二行遍历剩下的n-2行…所有行都遍历 上三角转换后，计算参数这里可以利用 n x (n+1)这一特性 python源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#coding=UTF-8###高斯消元法实现#############def Gauss(data): ##i是列元素j是控制循环的次数，line是存储一行元素 i=0 j=0 line_size=len(data) while j&lt;line_size-1: ###得到数据中的行 line=data[j] temp=data[j][j] templete=[] for x in line: x=x/temp templete.append(x) data[j]=templete flag=j+1 ######遍历第1行以后的行 while flag&lt;line_size: templete1=[] temp1=data[flag][j] i=0 ####将行的每一个元素与第一行相减 for x1 in data[flag]: if x1 !=0: x1=x1-(temp1*templete[i]) templete1.append(x1) else: templete1.append(0) i+=1 data[flag]=templete1 flag+=1 ##第一个参数已经消去，遍历消去剩下的参数 j+=1 #################对得到的上三角矩阵计算参数########### ''' [1,2,3,4,5 0,2,3,4,5 0,0,4,5,6 0,0,0,1,3 ] ''' parameter=[] parameter.append(data[line_size-1][-1]/data[line_size-1][-2]) ##parameter的下标刚好是所有参数剪切 #####从倒数第二列开始计算参数# i=line_size-2 while i &gt;=0: sum=0 parameter1=0 #这里分别进行回带，通过paramete数组 for j in range(i+1,line_size): sum+=parameter[line_size-1-j]*data[i][j] parameter1=(data[i][-1]-sum)/data[i][i] parameter.append(parameter1) i=i-1 return(parameter)#####进行消元测试#######parameters=[[6,15, 55,152.6],[15, 55, 225, 585.6],[55,225,979,2488.8] ]results=Gauss(parameters)print("x1="+str(results[-1])+"\nx2="+str(results[-2])+"\nx3="+str(results[0])+"\n") 总结其实思想很简单，代码实现的时候有一些小技巧 关于python画图的画等有时间再进行摸索吧 参考 https://blog.csdn.net/deramer1/article/details/79049625]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最小二乘python实现]]></title>
    <url>%2FBlog%2Farchives%2F6c33c6ae.html</url>
    <content type="text"><![CDATA[什么是最小二乘法通常用来对改定数据集D做线性回归，找到一条最逼近整个数据集的直线；在这里我只使用了一个属性到y的映射，其实也有多个属性可以同时进行映射，就需要用到降维的思想，例如我们有一对刮南瓜、西瓜、黄瓜；既可以使用三个坐标系将它们进行刻画。 让拟合直线上的每一个点距离D中的点的离均差的误差最小 Σ1m(f(xi)-yi)2 推理步骤 当所有样本到直线上的点最小时，相当于对K和b求偏导为0 分别对k和b的公式进行转换，得到k和b的值 我发现它必定要过（x,y）的平均值的那个点 python实现12345678910111213141516171819202122232425262728293031323334353637383940#coding=UTF-8&apos;&apos;&apos;进行一元数据的拟合&apos;&apos;&apos;x=[1,2,3,4,5,6,7]y=[3,4,5,6,7,8,9]###计算拟合参数######def lineFitting(data_x,data_y): ###获取集合中样本数目 size=len(data_x) ##构造遍历索引变量 i=0 ###声明公式中的变量 sum_x=0 sum_y=0 sum_Xsquare=0 sum_xy=0 average_x=0 average_y=0 ######对各个变量进行赋值 while i&lt;size: sum_x+=data_x[i] sum_y+=data_y[i] sum_Xsquare+=data_x[i]*data_x[i] sum_xy+=data_x[i]*data_y[i] i+=1 average_x=sum_x/size average_y=sum_y/size ###获取各个参数后直接套公式#### k=(sum_xy-sum_y*average_x)/(sum_Xsquare-sum_x*average_x) b=average_y-k*average_x return [k,b]#########计算拟合后的参数#########fittingParameter=lineFitting(x,y)print(&quot;y=&quot;+str(fittingParameter[0])+&quot;*x&quot;+&quot;+&quot;+str(fittingParameter[1])+&quot;\n&quot;) 绘图最后本来打算画一个图的，但是在服务器上跑脚本，图片就算了吧]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【持续更新】关于hexo博客的搭建]]></title>
    <url>%2FBlog%2Farchives%2Fd86fd5e9.html</url>
    <content type="text"><![CDATA[Quick start关于如何进行安装hexo和一些配置插件的过程我这里就不详细介绍了；大家可以百度网上一大堆，当然我这里推荐一些讲的比较好的博客遇见西门里面介绍了如何进行hexo的安装与主题的优化 插件的配置我使用的是gitment，还是对github比较有好感，具体教程参考：gitment 永久链接的配置借助于hexo-abbrlink插件，安装好之后呢；在博客目录下的配置文件中修改_config.yml文件就ok，具体的修改方式如下1234permalink: archives/:abbrlink.htmlabbrlink: alg: crc32 rep: hex 参考 关于在github二级仓库中构建博客 首先是在博客目录下的配置文件中进行设置 12url: https://zpliu1126.github.io/hexoTestroot: /hexoTest/ 接着就是关于搜素插件如何找到对应文件路径设置 12/*#######设置数据库所在文件*/xhr.open('GET', '/hexoTest/content.json', true); 由于该主题作者 Snippet并没有考虑到这一情况，我是在获取conten.js的路径中进行了修改 对应找到对应的数据文件之后进行路径的构造12/*关于在搜素结果content.json获取数据后加上子repository名构造最后url*/ path: "hexoTest/"+post.path, 其实就是一个字符串拼接的过程 关于文章如何进行分类的问题 1.在theme配置文件中打开category和tag标签 2.接着在每一个生成的文章中需要定义好category和tag内容才能进行跳转 3.同时在theme配置文件中可以定义好一些目录的跳转链接 123456789101112131415161718192021 #########文章的开头########## ---title: 关于hexo博客的搭建abbrlink: d86fd5e9date: 2019-03-05 18:06:07category: computerLanguagetag: - JavaScript - html - css---######导航栏##########menu:- page: home url: /hexoTest icon:- page: 计算机程序 url: /hexoTest/categories/computerLanguage/ icon:- page: Bioinformatic url: /hexoTest/categories/Bioinformatic/ 添加背景音乐 首先在网页版网易云找到喜欢的音乐，点击添加外部播放器有html和flash版本 我选择html版本，然后在theme的部署文件里随便找了个地方放了进去 最后调整播放框的大小 文章加密访问 基于插件访问 1hexo-blog-encrypt 修改根目录配置文件 1234# Security##encrypt: enable: true 在文章头部加上password字段 参考文章加密]]></content>
      <categories>
        <category>computerLanguage</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>html</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地Blast教程]]></title>
    <url>%2FBlog%2Farchives%2Fd57c3785.html</url>
    <content type="text"><![CDATA[blast+安装 通过wget 命令直接下载到本地服务器中 1wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.2.30+-x64-linux.tar.gz 对下载好的文件进行解压 1tar -zxvf ncbi-blast-2.2.30+-x64-linux.tar.gz 解压之后，其实就可以使用绝对路径使用blast+了；怎么知道blast的绝对路径呢 123pwd ncbi-blast-2.2.30+-x64-linux.tar.gz/bin ######例如我们得到这样的绝对路径##########/home/local/software/ncbi-blast-2.2.30+-x64-linux/bin/ 这条命令就得到了我们blast可执行程序所在的绝对路径，也就是在电脑上的哪个文件夹 有了绝对路径我们就可以告诉计算机到哪里去找balst程序来执行当执行blastn核苷酸比对程序时直接使用下面的命令就可以执行了1/home/local/software/ncbi-blast-2.2.30+-x64-linux/bin/blastn 添加可执行程序到环境变量中 首先环境变量是啥？环境变量其实就是一个变量，这个变量里面包括一个叫$PATH的变量，里面存储着一些你想告诉计算机的东西。比如我想告诉计算机blast+的所有可执行的程序都放在哪个文件里面，我只需要在$PATH这个变量中加上blast/bin的文件夹；这样当我们在计算机的任何地方想要执行balst的时候只需要按下blastn或者其他命令就行了12echo &quot;export PATH=/home/local/software/ncbi-blast-2.2.30+-x64-linux/bin:\$PATH&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc blast的使用构建本地blast库例如要构建核酸库，使用整个CDS构建的基因序列库1makeblastdb -in &quot;CDS文件&quot; -dbtype &quot;nucl&quot; -parse_seqids -out &quot;库名称的前缀&quot; 具体参数的意义可以使用 -help参数查看手册，我就不多做赘述同理构建蛋白库1makeblastdb -in &quot;氨基酸序列文件&quot; -dbtype &quot;prot&quot; -parse_seqids -out &quot;库名称的前缀&quot; 进行序列比对 首先我们需要准备比对的fasta文件，然后一条命令就可以了1blastn -query &quot;需要比对的文件&quot; -db &quot;上一步建好的库的目录加上/库前缀&quot; -evalue 1e-5 -outfmt 6 -out &quot;输出文件&quot; 这里的outfmt是输出文件的格式，包括1-10种格式 具体参数的意义，可以使用–help参数查看]]></content>
      <categories>
        <category>Bioinformatic</category>
      </categories>
      <tags>
        <tag>Blast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型评估与选择]]></title>
    <url>%2FBlog%2Farchives%2F7d1dcda7.html</url>
    <content type="text"></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础篇]]></title>
    <url>%2FBlog%2Farchives%2F53d0684b.html</url>
    <content type="text"></content>
      <categories>
        <category>computerLanguage</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Circos其实很简单]]></title>
    <url>%2FBlog%2Farchives%2F87ef918.html</url>
    <content type="text"><![CDATA[links中rule规则让color颜色与第二个连接点的颜色相同color = eval(var(chr2))]]></content>
      <categories>
        <category>Bioinformatic</category>
      </categories>
      <tags>
        <tag>Circos学习</tag>
      </tags>
  </entry>
</search>
